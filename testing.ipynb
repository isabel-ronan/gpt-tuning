{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing - Step 5\n",
    "\n",
    "- We will use ROUGE-1, ROUGE-2, ROUGE-L (sentence-level), ROUGE-L (summary-level), BERTScore (accepting truncation) from the original [ACI-Bench paper](https://www.nature.com/articles/s41597-023-02487-3) and also work by Liu et al. on non-fine-tuned [ChatGPT](https://doi.org/10.1186/s12911-024-02481-8). \n",
    "- In the ACI-Bench paper, GPT-4 exhibited the best performance, but was not fine-tuned on the ACI-BENCH clinical note format. \n",
    "- In the paper by Liu et al. ChatGPT paper, GPT-3.5 exhibited good performance, but was also not fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabel/anaconda3/envs/gpt-tuning/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "# for evaluation of results\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import BERTScorer # use BERTScore and accept truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # load environment variables from .env file\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test files\n",
    "dfs = []\n",
    "for file in os.listdir('./clinical_visit_note_summarization_corpus/data/aci-bench/challenge_data/'):\n",
    "    if 'test' in file and 'metadata' not in file:\n",
    "        dfs.append(pd.read_csv(f'./clinical_visit_note_summarization_corpus/data/aci-bench/challenge_data/{file}'))\n",
    "all_dfs = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_note_testing(model_name, all_dfs, save_file):\n",
    "  ai_generated_notes = []\n",
    "  for i in range(len(all_dfs['dialogue'])):\n",
    "    completion = client.chat.completions.create(\n",
    "      model=model_name,\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert medical professional. Given a clinical dialogue, create a clinical note outlining key dialogue aspects such as 'CHIEF COMPLAINT' (or 'CC'), 'HISTORY OF PRESENT ILLNESS' ('HPI'), 'REVIEW OF SYSTEMS', 'PHYSICAL EXAMINATION', 'VITALS REVIEWED', 'RESULTS', 'ASSESSMENT AND PLAN', 'INSTRUCTIONS', 'CURRENT MEDICATIONS', 'PAST MEDICAL HISTORY', 'EXAM', 'IMPRESSION', 'PLAN', 'ASSESSMENT', 'PAST HISTORY', 'ALLERGIES', 'SOCIAL HISTORY', 'PHYSICAL EXAM', 'PROCEDURE', 'FAMILY HISTORY', 'MEDICATIONS', 'VITALS', 'MEDICAL HISTORY', 'SURGICAL HISTORY'. You will not use all of these aspects in every dialogue, vary it from dialogue to dialogue.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Dialogue: {all_dfs['dialogue'][i]}\"}\n",
    "      ]\n",
    "    )\n",
    "    ai_generated_notes.append(completion.choices[0].message.content)\n",
    "  new_dataframe = {'dialogue': all_dfs['dialogue'], 'human_note': all_dfs['note'], 'ai_note':ai_generated_notes}\n",
    "  new_dataframe = pd.DataFrame(new_dataframe)\n",
    "  if '.csv' in save_file:\n",
    "    save_file = save_file.replace('.csv', '')\n",
    "  new_dataframe.to_csv(f'./testing_files/{save_file}.csv')\n",
    "  return new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_note_testing(\"ft:gpt-3.5-turbo-0125:personal:id0-0-5-3-1:9lHCKWt6\", all_dfs, \"id0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = [\"ft:gpt-3.5-turbo-0125:personal:id0-0-5-3-1:9lHCKWt6\", \"ft:gpt-3.5-turbo-0125:personal:id1-0-5-3-32:9lH86WrE\", \"ft:gpt-3.5-turbo-0125:personal:id2-0-5-3-67:9lH8UvK4\", \"ft:gpt-3.5-turbo-0125:personal:id3-0-5-10-1:9lHvfLG8\", \"ft:gpt-3.5-turbo-0125:personal:id4-0-5-10-32:9lHdGty4\", \"ft:gpt-3.5-turbo-0125:personal:id5-0-5-10-67:9lHc7RWd\", \"ft:gpt-3.5-turbo-0125:personal:id6-1-3-1:9lInZ0Yi\", \"ft:gpt-3.5-turbo-0125:personal:id7-1-3-32:9lIiZDyS\", \"ft:gpt-3.5-turbo-0125:personal:id8-1-3-67:9lIhXPXC\", \"ft:gpt-3.5-turbo-0125:personal:id9-1-10-1:9lJxwuWa\", \"ft:gpt-3.5-turbo-0125:personal:id10-1-10-32:9lJkMCw1\", \"ft:gpt-3.5-turbo-0125:personal:id11-1-10-67:9lJkGqJ5\", \"ft:gpt-3.5-turbo-0125:personal:id12-2-3-1:9lJz2sxA\", \"ft:gpt-3.5-turbo-0125:personal:id13-2-3-32:9lJt3emA\", \"ft:gpt-3.5-turbo-0125:personal:id14-2-3-67:9lK2HhyF\", \"ft:gpt-3.5-turbo-0125:personal:id15-2-10-1:9lKVnn72\", \"ft:gpt-3.5-turbo-0125:personal:id16-2-10-32:9lKCyb7z\", \"ft:gpt-3.5-turbo-0125:personal:id17-2-10-67:9lKF9kn8\"]\n",
    "for i in range(len(list_of_models)):\n",
    "    if i != 0:\n",
    "        model_note_testing(list_of_models[i], all_dfs, f\"id{i}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- time taken to cycle through all hyperparameterised models - 326m 50.4s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>human_note</th>\n",
       "      <th>ai_note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[doctor] hi , andrew . how are you ?\\n[patient...</td>\n",
       "      <td>CHIEF COMPLAINT\\n\\nUpper respiratory infection...</td>\n",
       "      <td>**CHIEF COMPLAINT (CC):**\\nPatient presents wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[doctor] hi andrea , how are you ?\\n[patient] ...</td>\n",
       "      <td>CHIEF COMPLAINT\\n\\nAnnual exam.\\n\\nHISTORY OF ...</td>\n",
       "      <td>**CHIEF COMPLAINT (CC):**\\n- 52-year-old femal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[doctor] hi , albert . how are you ?\\n[patient...</td>\n",
       "      <td>CHIEF COMPLAINT\\n\\nER follow-up.\\n\\nHISTORY OF...</td>\n",
       "      <td>**CHIEF COMPLAINT**:\\n- Emergency room follow-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[doctor] hi jerry , how are you doing ?\\n[pati...</td>\n",
       "      <td>CHIEF COMPLAINT\\n\\nAnnual exam.\\n\\nHISTORY OF ...</td>\n",
       "      <td>**CHIEF COMPLAINT (CC):** Insomnia and follow-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[doctor] hello , mrs . martinez . good to see ...</td>\n",
       "      <td>CC:\\n\\nRight arm pain.\\n\\nHPI:\\n\\nMs. Martinez...</td>\n",
       "      <td>**Clinical Note:**\\n- **CC (Chief Complaint):*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>[doctor] good afternoon matthew how are you\\n[...</td>\n",
       "      <td>CHIEF COMPLAINT\\n\\nVision changes in the right...</td>\n",
       "      <td>**CHIEF COMPLAINT (CC):**\\n- Vision changes, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>[doctor] okay well hi joe i understand you've ...</td>\n",
       "      <td>CHIEF COMPLAINT\\n\\nRight knee injury.\\n\\nHISTO...</td>\n",
       "      <td>**CHIEF COMPLAINT:**  \\nPatient presents with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>[doctor] hey angela how are you\\n[patient] i'm...</td>\n",
       "      <td>CHIEF COMPLAINT\\n\\nFollow-up of stage III non-...</td>\n",
       "      <td>**CHIEF COMPLAINT:**\\n- Follow-up on neo-adjuv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>[doctor] hey joshua good to see you today so t...</td>\n",
       "      <td>CHIEF COMPLAINT\\n\\nRight flank pain.\\n\\nHISTOR...</td>\n",
       "      <td>**CHIEF COMPLAINT:** Patient presents with rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>[doctor] hi frank how are you i heard the medi...</td>\n",
       "      <td>CHIEF COMPLAINT\\n\\nShortness of breath.\\n\\nMED...</td>\n",
       "      <td>**CHIEF COMPLAINT (CC):**  \\nShortness of brea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              dialogue  \\\n",
       "0    [doctor] hi , andrew . how are you ?\\n[patient...   \n",
       "1    [doctor] hi andrea , how are you ?\\n[patient] ...   \n",
       "2    [doctor] hi , albert . how are you ?\\n[patient...   \n",
       "3    [doctor] hi jerry , how are you doing ?\\n[pati...   \n",
       "4    [doctor] hello , mrs . martinez . good to see ...   \n",
       "..                                                 ...   \n",
       "115  [doctor] good afternoon matthew how are you\\n[...   \n",
       "116  [doctor] okay well hi joe i understand you've ...   \n",
       "117  [doctor] hey angela how are you\\n[patient] i'm...   \n",
       "118  [doctor] hey joshua good to see you today so t...   \n",
       "119  [doctor] hi frank how are you i heard the medi...   \n",
       "\n",
       "                                            human_note  \\\n",
       "0    CHIEF COMPLAINT\\n\\nUpper respiratory infection...   \n",
       "1    CHIEF COMPLAINT\\n\\nAnnual exam.\\n\\nHISTORY OF ...   \n",
       "2    CHIEF COMPLAINT\\n\\nER follow-up.\\n\\nHISTORY OF...   \n",
       "3    CHIEF COMPLAINT\\n\\nAnnual exam.\\n\\nHISTORY OF ...   \n",
       "4    CC:\\n\\nRight arm pain.\\n\\nHPI:\\n\\nMs. Martinez...   \n",
       "..                                                 ...   \n",
       "115  CHIEF COMPLAINT\\n\\nVision changes in the right...   \n",
       "116  CHIEF COMPLAINT\\n\\nRight knee injury.\\n\\nHISTO...   \n",
       "117  CHIEF COMPLAINT\\n\\nFollow-up of stage III non-...   \n",
       "118  CHIEF COMPLAINT\\n\\nRight flank pain.\\n\\nHISTOR...   \n",
       "119  CHIEF COMPLAINT\\n\\nShortness of breath.\\n\\nMED...   \n",
       "\n",
       "                                               ai_note  \n",
       "0    **CHIEF COMPLAINT (CC):**\\nPatient presents wi...  \n",
       "1    **CHIEF COMPLAINT (CC):**\\n- 52-year-old femal...  \n",
       "2    **CHIEF COMPLAINT**:\\n- Emergency room follow-...  \n",
       "3    **CHIEF COMPLAINT (CC):** Insomnia and follow-...  \n",
       "4    **Clinical Note:**\\n- **CC (Chief Complaint):*...  \n",
       "..                                                 ...  \n",
       "115  **CHIEF COMPLAINT (CC):**\\n- Vision changes, t...  \n",
       "116  **CHIEF COMPLAINT:**  \\nPatient presents with ...  \n",
       "117  **CHIEF COMPLAINT:**\\n- Follow-up on neo-adjuv...  \n",
       "118  **CHIEF COMPLAINT:** Patient presents with rig...  \n",
       "119  **CHIEF COMPLAINT (CC):**  \\nShortness of brea...  \n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform model testing on default gpt model\n",
    "model_note_testing(\"gpt-3.5-turbo-0125\", all_dfs, 'no-fine-tuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Test Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_scores = []\n",
    "bert = BERTScorer(model_type=\"bert-base-uncased\")\n",
    "rouge = rouge_scorer.RougeScorer(['rouge1','rouge2', 'rougeL', 'rougeLsum'], use_stemmer=True, split_summaries=True)\n",
    "for file in sorted(os.listdir('./testing_files/')):\n",
    "    if  'csv' in file:\n",
    "        temp_df = pd.read_csv(f\"./testing_files/{file}\")\n",
    "        df_list = []\n",
    "        for i in range(len(temp_df)):\n",
    "            scores = rouge.score(temp_df['human_note'][i], temp_df['ai_note'][i])\n",
    "            P, R, F1 = bert.score([temp_df['ai_note'][i]], [temp_df['human_note'][i]]) \n",
    "            temp_row = {'rouge1': scores['rouge1'].fmeasure, 'rouge2': scores['rouge2'].fmeasure, 'rougeL': scores['rougeL'].fmeasure, 'rougeLsum': scores['rougeLsum'].fmeasure, 'bertScore': F1}\n",
    "            df_list.append(temp_row)\n",
    "        df = pd.DataFrame(df_list)\n",
    "        average_scores.append({'id': file.replace('.csv', ''), 'rouge1': float(df['rouge1'].mean()), 'rouge2': float(df['rouge2'].mean()), 'rougeL': float(df['rougeL'].mean()), 'rougeLsum': float(df['rougeLsum'].mean()), 'bertScore': float(df['bertScore'].mean()), 'average': (float(df['rouge1'].mean()) + float(df['rouge2'].mean()) + float(df['rougeL'].mean()) + float(df['rougeLsum'].mean()) + float(df['bertScore'].mean())) / (5)})\n",
    "all_scores_df = pd.DataFrame(average_scores) \n",
    "all_scores_df.loc[len(all_scores_df.index)] = ['average', all_scores_df['rouge1'].mean(), all_scores_df['rouge2'].mean(), all_scores_df['rougeL'].mean(), all_scores_df['rougeLsum'].mean(), all_scores_df['bertScore'].mean(), all_scores_df['average'].mean()]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id    rouge1    rouge2    rougeL  rougeLsum  bertScore  \\\n",
      "0   default-aci-bench  0.547839  0.233264  0.288649   0.532430   0.683181   \n",
      "1                 id0  0.461466  0.161440  0.222590   0.447362   0.645535   \n",
      "2                 id1  0.488685  0.189492  0.254347   0.473521   0.646551   \n",
      "3                id10  0.504063  0.183951  0.241418   0.489548   0.659889   \n",
      "4                id11  0.461714  0.156300  0.219464   0.446362   0.642121   \n",
      "5                id12  0.552501  0.236541  0.296557   0.538425   0.687813   \n",
      "6                id13  0.401571  0.121552  0.180548   0.388084   0.617024   \n",
      "7                id14  0.429907  0.139586  0.203204   0.414540   0.632077   \n",
      "8                id15  0.601781  0.299588  0.354807   0.587760   0.715227   \n",
      "9                id16  0.548803  0.225141  0.284379   0.532322   0.682128   \n",
      "10               id17  0.500529  0.182463  0.237837   0.484936   0.654692   \n",
      "11                id2  0.483402  0.185078  0.252262   0.465780   0.642909   \n",
      "12                id3  0.543768  0.229418  0.288666   0.528047   0.683086   \n",
      "13                id4  0.457773  0.151502  0.214276   0.443538   0.637459   \n",
      "14                id5  0.425489  0.131340  0.194311   0.411637   0.627834   \n",
      "15                id6  0.518723  0.201025  0.263795   0.503598   0.673006   \n",
      "16                id7  0.431251  0.139421  0.202982   0.416744   0.629479   \n",
      "17                id8  0.484294  0.183704  0.250880   0.468148   0.645475   \n",
      "18                id9  0.579605  0.274228  0.331028   0.565180   0.701950   \n",
      "19     no-fine-tuning  0.474261  0.176299  0.249169   0.456341   0.632515   \n",
      "20            average  0.494871  0.190067  0.251558   0.479715   0.656998   \n",
      "\n",
      "     average  \n",
      "0   0.457073  \n",
      "1   0.387678  \n",
      "2   0.410519  \n",
      "3   0.415774  \n",
      "4   0.385192  \n",
      "5   0.462367  \n",
      "6   0.341756  \n",
      "7   0.363863  \n",
      "8   0.511832  \n",
      "9   0.454555  \n",
      "10  0.412091  \n",
      "11  0.405886  \n",
      "12  0.454597  \n",
      "13  0.380910  \n",
      "14  0.358122  \n",
      "15  0.432029  \n",
      "16  0.363976  \n",
      "17  0.406500  \n",
      "18  0.490398  \n",
      "19  0.397717  \n",
      "20  0.414642  \n"
     ]
    }
   ],
   "source": [
    "print(all_scores_df)\n",
    "all_scores_df.to_csv('./testing_files/testing_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
