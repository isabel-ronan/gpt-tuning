{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # load environment variables from .env file\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare test files\n",
    "dfs = []\n",
    "for file in os.listdir('./clinical_visit_note_summarization_corpus/data/aci-bench/challenge_data/'):\n",
    "    if 'test' in file and 'metadata' not in file:\n",
    "        dfs.append(pd.read_csv(f'./clinical_visit_note_summarization_corpus/data/aci-bench/challenge_data/{file}'))\n",
    "all_dfs = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_note_testing(model_name, all_dfs, save_file):\n",
    "  ai_generated_notes = []\n",
    "  for i in range(len(all_dfs['dialogue'])):\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"ft:gpt-3.5-turbo-0125:personal:default-aci-bench:9lDAbkNy\",\n",
    "      messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert medical professional. Given a clinical dialogue, create a clinical note outlining key dialogue aspects such as 'CHIEF COMPLAINT' (or 'CC'), 'HISTORY OF PRESENT ILLNESS' ('HPI'), 'REVIEW OF SYSTEMS', 'PHYSICAL EXAMINATION', 'VITALS REVIEWED', 'RESULTS', 'ASSESSMENT AND PLAN', 'INSTRUCTIONS', 'CURRENT MEDICATIONS', 'PAST MEDICAL HISTORY', 'EXAM', 'IMPRESSION', 'PLAN', 'ASSESSMENT', 'PAST HISTORY', 'ALLERGIES', 'SOCIAL HISTORY', 'PHYSICAL EXAM', 'PROCEDURE', 'FAMILY HISTORY', 'MEDICATIONS', 'VITALS', 'MEDICAL HISTORY', 'SURGICAL HISTORY'. You will not use all of these aspects in every dialogue, vary it from dialogue to dialogue.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Dialogue: {all_dfs['dialogue'][i]}\"}\n",
    "      ]\n",
    "    )\n",
    "    ai_generated_notes.append(completion.choices[0].message.content)\n",
    "  new_dataframe = {'dialogue': all_dfs['dialogue'], 'human_note': all_dfs['note'], 'ai_note':ai_generated_notes}\n",
    "  new_dataframe = pd.DataFrame(new_dataframe)\n",
    "  if '.csv' in save_file:\n",
    "    save_file = save_file.replace('.csv', '')\n",
    "  new_dataframe.to_csv(f'./testing_files/{save_file}.csv')\n",
    "  return new_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = model_note_testing(\"ft:gpt-3.5-turbo-0125:personal:default-aci-bench:9lDAbkNy\", all_dfs, \"default-aci-bench\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
